* Designing Typeahead Suggestion
    - Let's design a real-time suggestion service which will recommend terms to 
      users as they enter text for searching.
    

* What is typeahead suggestion?
    - Enables users to search for known and frequently searched terms. 
    - As the user tpyes into the earch box, it tries to predict the query 
      based on the characters the users has entered and gives a list of 
      suggestions to complete the query. 
    - Helps the user to articulate their search queries better. 
    - Not about speeding up the search process, but rather about guiding 
      the users and lending them a helping hand in constructing their 
      search query. 


* Requirements and Goals of the System 
    - Functional Requirements 
        * As the user types in their query, our service should suggest top 10 terms
          starting with whatever the user has typed 
    - Non Functional Requirements 
        * Suggestion should appear in real-time.
        * User should be able to see suggestoin within 200ms. 


* Basic System Design and Algorithm 
    - Trying to solve problem of that we have a lot of 'strings' that we need 
      to store in such a way that users can search with any prefix. 
    - Our service will suggest the next terms matching the given prefix 
    - For example, if our database contains the following terms: 
      cap, cat, captain, or capital, and the user has typed in ‘cap’, 
      our system should suggest ‘cap’, ‘captain’ and ‘capital’.
    - As we have to serve a lot of queries with minimum latency, 
      we need to come up with a scheme that can efficiently store our data 
      such that it can be queried quickly. We can’t depend upon some database 
      for this; we need to store our index in memory in a highly efficient data 
      structure.
    - One of the most appropriate data structures that can serve our purpose is 
      the Trie (pronounced “try”). A trie is a tree-like data structure used to 
      store phrases where each node stores a character of the phrase in a sequential
      manner. For example, if we need to store ‘cap, cat, caption, captain, capital’ 
      in the trie, it would look like:
    - Now if the user has typed ‘cap’, our service can traverse the trie to go to 
      the node ‘P’ to find all the terms that start with this prefix (e.g., cap-tion, 
      cap-ital etc).
    - We can merge nodes that have only one branch to save storage space. 
      The above trie can be stored like this:
    - Should we have case insensitive trie? 
        * For simplicity and search use-case, let’s assume our data is case 
          insensitive.
    - How to find top suggestion?
        * Store count of searches terminated at each node and return 
          top counts under the current prefix 
    - Given a prefix, how much time will it take to traverse its subtree?
        * Given amount of data we need to index, we should expect a huge tree. 
        * Even traversing a sub-tree would take really long
            - i.e. "system design interview questions' is 30 levels deep 
        * Have very strict latency requirements so must improve efficiency of our 
          solution. 
    - Can we store top suggestions with each node?
        * This can surely speed our searches but will require a lot of extra storage.
        * We can store top 10 suggestions at each node that we can return to the user. 
        * We have to bear the big increase in our storage capacity to achieve the required 
          efficiency. 
        * We can optimize our storage by storing only references of the terminal nodes 
          rather than storing the entire phrase.
        * To find the suggested terms we need to traverse back using the parent 
          reference from the terminal node. 
        * We will also need to store the frequency with each reference to keep track of 
          top suggestions. 
    - How would we build this trie?
        * We can efficiently build our trie bottom up.
        * Each parent node will recursively call all the child nodes to calculate 
          their top suggestions and counts. 
        * Parents nodes will combine top suggestions from all of their children to 
          determine their top suggestion.
    - How to update the trie?
        * Assuming five billion search every day, which would give us approximately 
          60K queries/second.
            - 5e9/(24*3600) < 5e9/(25*3000) = 500/75*1e7/1e3 ~= 6.66e4 ~= 60K queries/sec 
        * Don't try to update after every query, but offline after an elapsed period 
          of time.
        * As new queries come in we can log them and also track their frequencies.
        * We can log every query or do sampling and log every 1000th query.
        * For example, if don't want to show a term which is search for less than 
          1000 times, its safe to log every 1000th search term. 
        * We can have a Map-Reduce (MR) set up to process all the logging periodically
            - Perhaps every hour 
            - These MR jobs will calculate frequencies of all search terms in the past 
              hour. 
            - We can then update our trie with this new data.
            - We can take the current snapshot of the trie and update it with all the new 
              terms and their frequencies.
            - We should do this offline as we don't want our read queries to be blocked by 
              update trie requests.
            - We have two options 
                * We can make a copy of the trie on each server to update it offline.
                  Once done we can switch to start using it and discard the old one. 
                * Another option is we can have a primary-secondary configuration for each 
                  trie server.
                    - We can update the secondary while the priamry is serving traffic. 
                    - Once the update is complete, we can make the secondary our new primary.
                    - We can later update our priamry, which can then start serving 
                      traffic too. 
    - How can we update the frequencies of typeahead suggestions?
        * Since we are storing frequencies of our typeahead suggestions with each 
          node, we need to update them too!
        * We can update only differences in frequencies rather than recounting all search
          terms from scratch. 
        * If we're keeping count of all the terms searched in the last 10 days, we'll 
          need to subtract the counts from the time period no longer included and 
          add the counts for the new time period being included. 
        * We can add and subtract frequencies based on Exponential Moving Average (EMA).
            - In EMA, we give more weight to the latest data. It's also known as the 
              exponentially weighted moving average. 
        * After inserting a new term in the trie, we'll go to the terminal node of the 
          phrase and increase its frequency. 
        * Since we're storing the top 10 queries in each node, it is possible that this 
          particular search term jumped into the top 10 queries of a few other nodes. 
            - So we need to update the top 10 queries of those nodes as well.
            - We have to traverse back from the node to all the way up to the root. 
            - For every parent, we check if the current query is part of the top 10.
            - If so, we update the corresponding frequency.
            - If not, we check if the current query's frequency is high enough to be part 
              of the top 10. If so, we isnert this new term and remove the term  
              with the lowest frequency. 
    - How can we remove a term from the trie?
        * Let's say we have to remove a term from the trie because of some legal issue
          or hate or piracy, etc. 
        * We can completely remove such terms from the trie when the regular update happens,
          meanwhile, we can add a filtering layer on each server which will remove any such 
          term before sending them to users.
    - What could be different ranking criteria for suggestions?
        * In addition to a simple count, for terms ranking, we have to consider other 
          factors too: i.e. freshness, user location, language, demographics, personal 
          history, etc. 


* Permanent Storage of the Trie 
    - How to stire trie in a file so that we can rebuild our trie easily? This be 
      needed when a machine restarts.
        * We can take a snapshot of our trie periodically and store it in a file.
        * This will enable us to rebuild a trie if the server goes down. 
        * To store, we can start with the root node and save the trie level-by-level.
        * With each node, we can store what character it contains and how many 
          children it has. 
        * Right after each node, we should put all of its children. 
        * i.e.
              root
               c
            a     o 
           r p    d 
           t 
        * We can store this trie in a file with teh above-mentioned scheme, we will have 
            c2 a2 r1 t1 p o1 d 
            --> Can rebuild trie using this representation 
        * Not storing top suggestions and their counts with each node. 
            - Hard to store this information as our trie is being stored top-down 
            - We dont' have child nodes created before the parent so no way to 
              store their references 
            - For this, we have to recalculate all the top terms with counts 
            - This can be done while we are building the trie.
            - Each node will calculate its top suggestions and pass it to its parent.
            - each parent node will merge results from all of its children to 
              figure out its top suggestions. 


* Scale Estimation 
    - If we are building a service that has the same scale as that of Google, we can 
      expect 5e9 searches every day, which would give us 60k queries per second. 
    - Since there will be a lot of duplicates in 5 billion queries, we can assume
      only 20% of these will be unique. If we only want to index the top 50% of the 
      search terms, we can get rid of a lot of less frequently searched queries. 
    - Let's assume we will have 100e6 unique terms for which we want to build an index. 
    - Storage Estimation 
        * If on average each query consists of 3 word and if the average length 
          of a word is 5 characters, this will use 15 characters of average query 
          size. 
        * Assuming we need 2 bytes to store a character, we will need 30 bytes 
          to store an average query.
            - Total storage we would need would be 
              --> 100e6 * 30 = 3 GB 
        * We can expect some growht in this data every day, but we should also be 
          removing some terms that are not searched anymore. 
        * If we assume we have 2% of new queries every day and if we are maintaing 
          our index for the last one year, total storage we should expect.
          --> 3GB + (0.02*365*3GB) = 3 + (365/50 * 3) ~= 3 + 21 = 24 GB 


* Data Partition 
    - Although our index can easily fit on one server, we can still partition it in 
      order to meet our requirements of higher efficiency and lower latencies.
    - How can we efficiently partition our data to distribute it onto multiple servers?
    - Range Based Partitioning
        * What if store our phrases in separate partitions on their first letter?
            - So we save all terms starting with the letter 'A' in one partition and those 
              that start with the letter 'B' into another partition, etc. 
            - We can even combine certain less frequently occuring letters into one partition.
            - Should come up with this partitioning scheme statically so that we can always 
              store and search terms in a predictable manner. 
            - Problems 
                * Can lead to unbalanced servers as some words will be mouch more/less 
                  frequent than others. 
                * Above problem will happen with any statically defined scheme. It is not possible 
                  to calculate if each of our partitions will fit on one server statically. 
    - Partition based on maximum capacity of the server 
        * Let's say we partition our trie based on the maximum memory capacity of the servers.
        * We can keep storing data on a server as long as it has memory available.
        * Whenever a sub-tree cannot fit into a server, we break our partition 
          there to assign that range to this server and move on to the next server 
          to repeat this process. 
        * Let's say if our first trie server can store all terms from 'A' to 'AABC',
          which means our next server will store from 'AABD' onwards.
        * If our second server could store up to 'BXA', the next server will start from 
          'BXB' and so on.
        * We can keep a hash table to quickly access the partitioning scheme.
            - Server1, A-AABC
            - Server2, AABD-BXA
            - Server3, BCB-CDA 
        * For querying, if we user has typed 'A' we have to query both servers 1 and 2 
          to find the top suggestions.
        * When the user has typed 'AA', we still have to query server 1 and 2, but when user 
          has typed 'AAA' we only need to query server 1. 
        * We can have a load balancer in front of our trie servers which can store this 
          mapping and redirect traffic.
        * Also, if we are querying from multiple servers, either we need to merge the 
          results on the server-side to calculate the overall top results, or make our 
          clients do that. 
        * We can have a load balancer in front of our trie servers which can store 
          this mapping and redirect traffic.
        * Also, if we are querying from multiple servers, either we need to merge the results on
          the server side to calculate the overall top results or make our clients do that.
        * If we prefer to this on the serverside, we need to introduce another layer 
          of servers between load balancers and trie servers --> aggregators 
        * Aggregration servers will aggregate results from multiple trie servers and 
          return the top result to the client. 
        * Partitioning basedo n the maximum capacity can still lead us to hotspots, 
          i.e. if there are a lot of queries for terms starting with 'cap', then the server 
          holding it will have a high load compared to others.
    - Partitioning based on the has of the term 
        * Each term will be passed to a hash function, which will generate a server number 
          and we will store the term on that server. Thsi make our term distribution
          random and minimize hotspots.
        * Disadvantage of this scheme is to find a typehead suggestions for a term we have 
          to ask all the server and then aggregate the results. 


* Cache 
    - We should realize that caching the top searched terms will be extremely helpful 
      in our service.
    - There will be a small percentage of queries that will be responsible for most 
      of the traffic.
    - We can have separate cache servers in front of the trie servers holding 
      the most frequently searched terms and their typeahead suggestions. 
    - Application servers should check these cache servers before hitting the trie servers 
      to see if they have the desired search terms. 
    - This will save us time to search the trie. 
    - We can build a simple machine learning model that can try to predict the 
      engagement of each suggestion based on simple counting, personalization,
      or trending data, and cache these terms beforehand. 


* Replication and Load Balancer 
    - We should have replicas for our trie servers both for load balancing 
      and also for fault tolerance.
    - We also need a load balancer that keeps track of our data partitioning 
      scheme and redirects traffic based on the prefixes.


* Fault Tolerance 
    - What will happen when a trie server goes down?
        * As discussed above we can have a primary-secondary configuration; if 
          the primary does, the secondary can take over after failover.
        * Any server that comes back up, can rebuild the trie based on the last snapshot.


* Typeahead Client 
    - We can perform the following optimizations on the client-side to improve 
      user's experience 
        * The client should only try hitting the server if the user has not 
          pressed any key for 50 ms 
        * If the user is constantly typing, the client can cancel the 
          inprogress requests 
        * Initially, the client can wait until the user enters a couple of characters
        * Cleints can pre-fetch some data from the server to save future requests 
        * Clients can store the recent history of suggestions locally. Recent 
          history has a very high rate of being reused. 
        * Establishing an early connection with the server turns out to be one 
          of the most important factors. 
            - As soon as the user opens the search engine website, the client can 
              open a connection with the server.
            - When a user types in the first character, the client doesn't time in establishing 
              the connection. 
        * The server can push some part of their cache to CDNs and ISPs for 
          efficiency. 


* Personalization 
    - Users will receive some typeahead suggestions based on their historical searches,
      location, language, etc. 
    - We can store the personal history of each user separately on the server and also 
      cache them on the client. 
    - The server can add these personalized terms in the final set before sending it 
      to the user.
    - Personalized searches should always come before others. 
        



    



