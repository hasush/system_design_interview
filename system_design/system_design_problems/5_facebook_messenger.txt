* Messaging service like Facebook messenger where users can message each other through
  web or mobile interfaces. 


* What is facebook messenger?
    - Software application which provides text-based instant messaging services
      to its users. Messenger users can chat with their Facebook friends both from 
      cell phone and Facebook's website. 


* Requirements and Goals of the System 
    - Functional Requirements 
        * Messenger should support one-on-one conversations between users. 
        * Messenger should keep track of hte online/offline statuses of its users 
        * Messenger should support the persistent storage of chat history 
    - Non functional requirements 
        * Users should have real-time chat experience with minimum latency.
        * System should be highly consistent. Users should see same chat history 
          on all their devices. 
        * High availability is desiarable; can tolerate lower availability in the 
          interest of consistency 
    - Extended Requirements 
        * Groups Chats: multiple people talking to each other 
        * Push notifications: Messenger should be able to notify users of new 
          messages when they are offline 
    

* Capacity Estimations and Constraints 
    - 500e6 active users 
    - Send 40 messages a day 
      --> 500e6*40=20e9 messages/day 
    - Storage Estimations
        * Average message size is 100 bytes 
        * Storage per day
          --> 20e9 * 100 = 2000e9=2TB/day 
        * 5 years 
          365*5*2TB = 365*10TB=3650TB/5years = 3.65 PB 
        * Also need to store users' information, messages' metadata (ID, timestamp,etc.)
        * Above calculation doesn't take data compression and replication into consideration.
        * Compression ratios
            * 1.5 lossless to 20x lossy for images 
            * 5x for text 
    - Bandwidth Estimation 
        * 2TB/day of data 
          --> 2e12/(24*3600) ~= 2e12/(25*4000) = 2e12/(1e5) = 10 MB/s (actually 25 MB/s)
        * Each message goes from user to user --> same bandwidth for upload and download
    

* High level design 
    - At a high-level, we will need a chat server that will be the central piece,
      orchestrating all the communications between users. 
    - When a user wants to send a message to another user, they send a message to the 
      central server which then sends the message to the other user and save the 
      message in the database. 
    

    user_a <----------->   chat   <-----> storage  
    user_b <----------->  server 

    - Detailed workflow 
        * user_a sends a message to user_b through the chat server 
        * the server receives the message and sends an acknowledgement to user_a 
        * The server stores the message in its database and sends the message to 
          user_b 
        * user_b receives the message and sends an acknowledgement to server 
        * The server notifies user_a that the message has been received by user_b 

* Detailed component design 
    - Lets try to build simple solution that runs on one server 
    - At high level, system needs to handle the following use case 
        * Receive incoming message and deliver outgoing message 
        * Store and retrieve messages from the database 
        * Keep a record of which user is online or has gone offline, and notify 
          all the relevant users about these status changes 
    - Messages Handling 
        * How would we efficiently send/receive messages?
            - To send messages, the user has to connect to the server and post messages 
              to the server. 
            - To get messages from the server, the user has two options
                * Pull model: Users can periodically ask the server if there are any new 
                  messages for them 
                * Push model: users can keep a connection open with the server and
                  can depend on the server to notify them whenever there are new messages 
            - If we go with second approach, where all active users keep a connection open 
              with the server, then as soon as the server receives a message, it can
              immediately pass the message to the intended user.
                * This way, server does not need to keep track of pending messages, and 
                  we will have minimum latency as the messages are delivered instantly on
                  the opened connection. 
        * How will clients maintain an open connection with the server?
            - We can use HTTP long polling or web sockets. 
            - Long Polling 
                * clients request information from the server with the expectation that the 
                  server may not respond immediately. 
                * If the server has no new data to give to the client when the poll is received,
                  instead of sending an empty response, it waits until it has new information 
                  to give to the client. 
                * Once server has new information, it immediately sends the information to the client. 
                * Upon receipt of the response, the client can immediately poll the server again
                  for future updates. 
                * This procedure greatily improves latency, throughputs, and performance. 
                * The long polling request can timeout or can receive a disconnect from the 
                  server, in that case, the client has to open a new request. 
        * How can the server keep track of all the opened connection to redirect messages 
          to the users efficiently? 
            - The server can maintain a hash table, where "key" would be the UserID and 
              "value" would the connection object.
            - Whenever the server receives a message for a user, it looks up that user in the hash table 
              table to find the connection object and sends the message on that open request. 
        * What will happen when the server receives a message for a user who has gone offline?
            - If the receiver has disconnected, the server can notify the sender about 
              the delivery failure.
            - If it is a temporary disconnect, i.e. the receiver's long poll request just time 
              out, then we should expect a reconnect from the user.
                - In this case can ask the sender to retry sending the message.
                - This retry could be embedded in the client's logic so that users don't have 
                  to retype the message. 
            - The server can also store the message for a while and retry sending it once the receiver 
              reconnects. 
        * How many chat server do we need?
            - Let's plan for 500e6 connections at any time. Assuming a modern server 
              can handle 50k concurrent connections at a time, we would need 10k such servers. 
        * How do we know which server holds the connection to which user?
            - We can introduce a software laod balancer in front of our chat servers
              so that we can direct each UserID to a server to redirect the request 
        * How should the server process a "deliver message" request?
            - The server needs the followings things when it receives a message
                * Store the message in the database 
                * Send the message to the receiver 
                * Send an acknowledgement to the sender 
            - The chat server will first find the server that holds the connection to
              the receiver and pass the message to that server to send it to the receiver.
            - The chat server can then send the acknowledgement to the sender
                * We don't need to wait to store the message in the database as that 
                  can happen in the background 
        * How does the messenger maintain the sequencing of the messages?
            - We can store a timestamp for each message, which is the time the message 
              is received by the server. 
            - This will still not ensure the correct ordering of messages for clients. 
            - The scenario where the server timestamp cannot determine the exact order 
              of messages would look like this:
                * user1 sends message m1 to server for user2 
                * the server recevies message m1 at time t1 
                * meanwhile, user2 sends a message m2 to the server for user1 
                * the server receives the message at time t2 such that t2>t1 
                * the server sends message m1 to user2 and m2 to user1 
                * This implies user1 will see m1 first and then m2 whereas user2 will see 
                  m2 first and then m1 
                * To resolve this, we need to keep a sequene number with every message
                  for each client. 
                * The sequence number will determine the exact ordering of messages for 
                  EACH user. 
                * With this solution, both clients will see a different view of the message
                  sequence, but this view will be consistent for them on all devices. 
    - Storing and retreiving the messages from the database 
        * Whenever a chat server receives a new message, it needs to store in the database
        * We have two options 
            - Start a separate thread which will work with the databse to store the message 
            - Send an asynchronous request to the databse to store the message 
        * Have to keep certain thigns in mind while designing our database 
            - How to efficiently work with the database connection pool 
            - How to retry failed requests 
            - Where to log those requests that failed even after some retries 
            - How to retry those logged requests (that failed after the retry) when
              all the issues have resolved?
        * Which storage system should we use?
            - We need to have a database that can support a very high rate of small 
              updates and also a fetch a range of records quickly. 
                * This is required because we have a huge number of small messages 
                  that need to be inserted in the database and while querying, 
                  a user is mostly interested in sequentially accessing the messages
            - We cannot use RDBMS like MySQl or NoSQL like MongoDB because we cannot 
              afford to read/write a row from the database every time a user 
              receives/sends a message. 
                * This would make the basic operations of our service run with 
                  high latency and also creat a huge load on databases 
            - Both requirements can be easily met with a wide-column database solution like
              HBase. 
                * HBase is a column-oriented key-value NoSQL database that can store 
                  multiple values against one key into multiple columns. 
                * Hbase is modeled after Google's BigTable and runs on top of HDFS 
                * Hbase groups data together to to store new data in a memory buffer and 
                  once the buffer is full, it dumps the data to the disk. 
                * This way of storage not only helps to store a lot of small data 
                  quickly, but also feteching rows by the key or scanning ranges of rows. 
                * HBase is also an efficient database to store variable-sized data, which is
                  also required by our service. 
        * How should clients efficiently fetch data from the server?
            - Clients should paginate while fetching the data from the server.
            - Page size could be different for different clients
                * I.e. cell phones have smaller screens so we need a fewer number of 
                  messages/conversations in the viewpoint 
    - Managing user's status 
        * We need to keep track of user's online/offline status and notify all the relevant 
          users whenever a status change happens. 
        * Since we are maintaining a connection object on the server for all active users,
          we can easily figure out the user's current status from this. 
        * With 500M active users at any time, if we have to broadcast each status change 
          to all the relevant active users, it will consume a lot of resources. 
        * We can do the following optimizations
            - Whenever a client starts the app, it can pull the current status of 
              all users in their friends' list 
            - Whenever a user sends a message to another use that has gone offline, we 
              can send a failure to the send a failure to the sender and update the status 
              of the client. 
            - Whenever a user comes online, the server can always broadcast that status
              with a delay of a few seconds to see if the user does not go offline 
              immediately. 
            - Clients can pull the status from the server about those users that are being shown
              on the user's viewpoint. This should not be a frequent operation as the 
              server is broadcasting the online status of users and we cna live with the 
              stale offline status of users for a while.
            - Whenever client starts a new chat with another user, we can pull the status
              at that time. 
            - See figure facebook_messenger_figure1.png 

            user_a------->
            user_b-------> LB
            user_c------->  |
                            |
                    ------------------
                    |     |    |     |
                    |     |    |     |
                    |     |    |     |
                    v     v    v     v              (User to Cache Server Mapping )
          chat_server_i  etc.  etc.  chat_server_j -------> Load Balancer 
                    |     |    |     |                             |
                    |     |    |     |                             |
                    |     |    |     |                             |
                    v     v    v     v                             v
            db_shard_m   etc.  etc.  db_shard_n ---------> cache_l etc. etc. cache_k


    - Design Summary 
        * Clients will open a connection the chat server to send a message;
            the server will then pass it to the request user
        * All active users will keep a connection open with the server to receive 
            messages 
        * Whenever a new message arrives, the chat server will push it to the 
            receiving user on the long poll request 
        * Messages can be stored in HBase which support quick small updates and 
          range based searches
        * The servers can broadcast the online status of a user to other relevant 
          users. 
        * Clients can pull the status updates for users who are visible in the clients 
          viewport on a less frequent basis. 


* Data partitioning 
    - We will be storing a lot of data (3.6 PB for five years).
    - Need to distribute on multiple database servers, partitioning scheme?
    - Partitioning based on UserID 
        * Let's assume we partition based on the hash of the UserID so that 
          we can keep all messages of a user on the same database. 
        * If one data shard is 4 TB, we will have 
          3.6e3 TB / 4 TB ~ 900 shards for five years 
        * Simplicity, consider 1000 shards 
        * Can then find shard number by UserID%1000 and then store/retrieve 
          the data from there.
        * This partitioning scheme also makes it very quick to fetech chat 
          history for any user.
        * In the beginning, we can start with fewer database servers 
          with multiple shards residing on one physical server. 
        * Since we can have multiple database instances on a server, we can easily 
          store multiple shards on a single server. 
        * Our hash functions needs to understand this logical partiioning 
          scheme so that it can map multiple logical partitions 
          on one physical server. 
        * Since we will store an unlimited history of messages, we can start with a 
          big number of logical partitions, which will be mapped to 
          fewer physical servers 
        * as our storage demand increases, we can add more physical servers to
          distribute our logical partitions 
    - Partioning basedo n MessageID
        * If we store different messages of a user on separate database shards, fetching
          a range of messages of a chat would be very slow so we should not 
          adopt this scheme. 


* Cache 
    - We can cache a few recent messages (say 15) in a few recent conversations that are 
      visible in a user's viewport (say last 5).
    - Since we decided to store all the user's messages on one shard, that cache for 
      a user should entirely reside on one machine too. 


* Load Balancing 
    - We will need to use an LB in front of our chat servers.
    - LB will map each UserID to a server that holds the connection for the user and
      then direct the request to that server.
    - Similarly, need LB for our cache servers as well 


* Fault tolerance and replication 
    - What will happen if a chat server fails?
        * Chat servers are holding connections with users.
        * If a server goes down, should we devise a mechanism to transfer these connections 
          to another server?
            - Extremely difficult to failover TCP connections to other servers 
            - WOuld be easier to force clients to reconnect if the connection is lost. 
    - Should we store multiple copies of messages?
        * We have to fail safes for if data storage crashes 
        * Need to have copies of the data on different servers 


* Extended Requirements 
    - Group Chat 
        * Can have separate group chat objects in our system that can be stored 
          on the chat servers 
        * A group chat object would be defined by GroupChatID and would also have 
          the list of users that are a part of that group chat.
        * Our LB can direct each group chat message based on GroupChatID and the server 
          handling that group chat can iterate through all the users of the chat to
          find the server handling the connection of each user to deliver the message. 
        * In our databases, we can store all the group chats in a separate table partitioned 
          based on a GroupChatID 
    - Push Notifications 
        * With current design, users can only send messages to active users and 
          if recepient is not online, a failed response will be sent to the sender.
        * Push notifications will also to send messages to offline users. 
        * Each user can opt-in from their device (or web browser) to get notifications 
          whenever there is a new message or event. 
        * Maintain a set of servers that handle pushing these notifications to users.
        * Need to set up a notification server which will take messages for offline 
          users and send them to push notification server which will then send 
          them to the user's device. 






    